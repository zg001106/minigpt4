#!/usr/bin/env python3
"""
MiniGPT-4 æ‰¹é‡å›¾ç‰‡æ¨ç†è„šæœ¬

ä½¿ç”¨æ–¹æ³•:
1. ä¿®æ”¹ä¸‹é¢çš„é…ç½®å‚æ•°
2. ç¡®ä¿æ‚¨çš„å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„æ­£ç¡®
3. è¿è¡Œè„šæœ¬: python batch_inference.py

è¾“å‡º:
- æ¯å¼ åŸå›¾ç‰‡åœ¨ä¸Šæ–¹
- MiniGPT-4çš„å›ç­”æ–‡æœ¬åœ¨ä¸‹æ–¹
- ä¿å­˜ä¸ºæ–°çš„å›¾ç‰‡æ–‡ä»¶
"""

import argparse
import os
import random
import numpy as np
import torch
import torch.backends.cudnn as cudnn
from PIL import Image, ImageDraw, ImageFont
import cv2

from minigpt4.common.config import Config
from minigpt4.common.dist_utils import get_rank
from minigpt4.common.registry import registry
from minigpt4.conversation.conversation import Chat, CONV_VISION_Vicuna0, CONV_VISION_LLama2

# imports modules for registration
from minigpt4.datasets.builders import *
from minigpt4.models import *
from minigpt4.processors import *
from minigpt4.runners import *
from minigpt4.tasks import *

# ===== é…ç½®å‚æ•° =====
# è¯·æ ¹æ®æ‚¨çš„å®é™…æƒ…å†µä¿®æ”¹ä»¥ä¸‹å‚æ•°

# è¾“å…¥å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆåŒ…å«è¦å¤„ç†çš„å›¾ç‰‡ï¼‰
INPUT_DIR = "examples"

# è¾“å‡ºç»“æœæ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå¤„ç†åçš„å›¾ç‰‡å°†ä¿å­˜åœ¨è¿™é‡Œï¼‰
OUTPUT_DIR = "output_results"

# æç¤ºè¯ï¼ˆæ‰€æœ‰å›¾ç‰‡éƒ½ä¼šä½¿ç”¨è¿™ä¸ªæç¤ºè¯ï¼‰
PROMPT = "Please describe this image in detail."

# é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆMiniGPT-4çš„é…ç½®æ–‡ä»¶ï¼‰
CFG_PATH = "eval_configs/minigpt4_eval.yaml"

# GPU IDï¼ˆå¦‚æœæœ‰å¤šä¸ªGPUï¼Œå¯ä»¥é€‰æ‹©ä½¿ç”¨å“ªä¸ªï¼‰
GPU_ID = 0

# å­—ä½“å¤§å°ï¼ˆç”¨äºåœ¨å›¾ç‰‡ä¸‹æ–¹æ˜¾ç¤ºæ–‡æœ¬ï¼‰
FONT_SIZE = 16

# ===== è„šæœ¬ä»£ç  =====

def setup_seeds(seed=42):
    """è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯é‡ç°"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    cudnn.benchmark = False
    cudnn.deterministic = True


def init_model(cfg_path, gpu_id=0):
    """åˆå§‹åŒ–MiniGPT-4æ¨¡å‹"""
    # æ¨¡æ‹Ÿå‘½ä»¤è¡Œå‚æ•°
    class Args:
        def __init__(self):
            self.cfg_path = cfg_path
            self.gpu_id = gpu_id
            self.options = None
    
    args = Args()
    cfg = Config(args)
    
    # å¯¹è¯æ¨¡ç‰ˆå­—å…¸
    conv_dict = {'pretrain_vicuna0': CONV_VISION_Vicuna0,
                 'pretrain_llama2': CONV_VISION_LLama2}
    
    print('ğŸš€ æ­£åœ¨åˆå§‹åŒ–MiniGPT-4æ¨¡å‹...')
    
    # æ¨¡å‹é…ç½®
    model_config = cfg.model_cfg
    model_config.device_8bit = gpu_id
    model_cls = registry.get_model_class(model_config.arch)
    model = model_cls.from_config(model_config).to(f'cuda:{gpu_id}')
    
    # å¯¹è¯æ¨¡ç‰ˆ
    CONV_VISION = conv_dict[model_config.model_type]
    
    # è§†è§‰å¤„ç†å™¨
    vis_processor_cfg = cfg.datasets_cfg.cc_sbu_align.vis_processor.train
    vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(vis_processor_cfg)
    
    # èŠå¤©å¯¹è±¡
    chat = Chat(model, vis_processor, device=f'cuda:{gpu_id}')
    print('âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ!')
    
    return chat, CONV_VISION


def process_single_image(image_path, prompt, chat, conv_vision):
    """å¤„ç†å•å¼ å›¾ç‰‡å¹¶è·å–å›ç­”"""
    try:
        # åˆ›å»ºå¯¹è¯çŠ¶æ€
        chat_state = conv_vision.copy()
        img_list = []
        
        # åŠ è½½å¹¶ä¸Šä¼ å›¾ç‰‡
        image = Image.open(image_path).convert('RGB')
        chat.upload_img(image, chat_state, img_list)
        chat.encode_img(img_list)
        
        # æé—®
        chat.ask(prompt, chat_state)
        
        # è·å–å›ç­”
        answer = chat.answer(conv=chat_state,
                            img_list=img_list,
                            num_beams=1,
                            temperature=1.0,
                            max_new_tokens=300,
                            max_length=2000)[0]
        
        return answer, image
        
    except Exception as e:
        print(f"âŒ å¤„ç†å›¾ç‰‡ {image_path} æ—¶å‡ºé”™: {str(e)}")
        return None, None


def create_combined_image(original_image, answer_text, font_size=20):
    """å°†å›ç­”æ–‡æœ¬æ·»åŠ åˆ°å›¾ç‰‡ä¸‹æ–¹"""
    # è½¬æ¢ä¸ºPILå›¾åƒ
    if isinstance(original_image, np.ndarray):
        original_image = Image.fromarray(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
    
    # å›¾ç‰‡å°ºå¯¸
    img_width, img_height = original_image.size
    
    # è®¾ç½®å­—ä½“ï¼ˆå°è¯•ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“ï¼‰
    try:
        # Windowsç³»ç»Ÿå­—ä½“
        font = ImageFont.truetype("arial.ttf", font_size)
    except:
        try:
            # å¤‡ç”¨å­—ä½“
            font = ImageFont.truetype("C:/Windows/Fonts/simhei.ttf", font_size)
        except:
            # é»˜è®¤å­—ä½“
            font = ImageFont.load_default()
    
    # è®¡ç®—æ–‡æœ¬åŒºåŸŸé«˜åº¦
    text_lines = []
    max_width = img_width - 20  # ç•™è¾¹è·
    words = answer_text.split(' ')
    current_line = ""
    
    # å°†æ–‡æœ¬åˆ†è¡Œ
    for word in words:
        test_line = current_line + word + " "
        try:
            bbox = font.getbbox(test_line)
            text_width = bbox[2] - bbox[0]
        except:
            # å¯¹äºæ—§ç‰ˆæœ¬PILï¼Œä½¿ç”¨textsize
            text_width = font.getsize(test_line)[0]
        
        if text_width <= max_width:
            current_line = test_line
        else:
            if current_line:
                text_lines.append(current_line.strip())
                current_line = word + " "
            else:
                text_lines.append(word)
                current_line = ""
    
    if current_line:
        text_lines.append(current_line.strip())
    
    # è®¡ç®—æ–‡æœ¬æ€»é«˜åº¦
    line_height = font_size + 5
    text_height = len(text_lines) * line_height + 20  # é¢å¤–è¾¹è·
    
    # åˆ›å»ºæ–°å›¾ç‰‡ï¼ˆåŸå›¾+æ–‡æœ¬åŒºåŸŸï¼‰
    new_height = img_height + text_height
    combined_image = Image.new('RGB', (img_width, new_height), 'white')
    
    # ç²˜è´´åŸå›¾
    combined_image.paste(original_image, (0, 0))
    
    # ç»˜åˆ¶æ–‡æœ¬
    draw = ImageDraw.Draw(combined_image)
    y_offset = img_height + 10
    
    for line in text_lines:
        draw.text((10, y_offset), line, fill='black', font=font)
        y_offset += line_height
    
    return combined_image


def batch_process_images(input_dir, output_dir, prompt, cfg_path, gpu_id=0, font_size=16):
    """æ‰¹é‡å¤„ç†å›¾ç‰‡æ–‡ä»¶å¤¹"""
    print("=" * 60)
    print("ğŸ¯ MiniGPT-4 æ‰¹é‡å›¾ç‰‡æ¨ç†")
    print("=" * 60)
    print(f"ğŸ“ è¾“å…¥ç›®å½•: {input_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ’¬ æç¤ºè¯: {prompt}")
    print(f"âš™ï¸ é…ç½®æ–‡ä»¶: {cfg_path}")
    print(f"ğŸ”§ GPU ID: {gpu_id}")
    print("=" * 60)
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(input_dir):
        print(f"âŒ é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return
    
    # è®¾ç½®éšæœºç§å­
    setup_seeds()
    
    # åˆå§‹åŒ–æ¨¡å‹
    chat, conv_vision = init_model(cfg_path, gpu_id)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•å·²åˆ›å»º: {output_dir}")
    
    # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
    
    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    image_files = []
    for file in os.listdir(input_dir):
        if any(file.lower().endswith(ext) for ext in image_extensions):
            image_files.append(file)
    
    if not image_files:
        print(f"âŒ é”™è¯¯: åœ¨ {input_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return
    
    print(f"ğŸ–¼ï¸ æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    print("=" * 60)
    
    # å¤„ç†æ¯å¼ å›¾ç‰‡
    success_count = 0
    for i, image_file in enumerate(image_files, 1):
        print(f"ğŸ”„ æ­£åœ¨å¤„ç† ({i}/{len(image_files)}): {image_file}")
        
        image_path = os.path.join(input_dir, image_file)
        
        # è·å–æ¨¡å‹å›ç­”
        answer, original_image = process_single_image(image_path, prompt, chat, conv_vision)
        
        if answer is not None and original_image is not None:
            # åˆ›å»ºç»„åˆå›¾ç‰‡
            combined_image = create_combined_image(original_image, answer, font_size)
            
            # ä¿å­˜ç»“æœ
            output_filename = f"result_{os.path.splitext(image_file)[0]}.jpg"
            output_path = os.path.join(output_dir, output_filename)
            combined_image.save(output_path, 'JPEG', quality=95)
            
            print(f"  âœ… ä¿å­˜åˆ°: {output_path}")
            print(f"  ğŸ’¬ å›ç­”: {answer[:80]}...")  # æ˜¾ç¤ºå‰80ä¸ªå­—ç¬¦
            success_count += 1
        else:
            print(f"  âŒ å¤„ç†å¤±è´¥")
        
        print()  # ç©ºè¡Œåˆ†éš”
    
    print("=" * 60)
    print(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ! æˆåŠŸå¤„ç† {success_count}/{len(image_files)} å¼ å›¾ç‰‡")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
    print("=" * 60)


if __name__ == "__main__":
    # æ£€æŸ¥é…ç½®
    if not os.path.exists(INPUT_DIR):
        print(f"âŒ é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {INPUT_DIR}")
        print("è¯·ä¿®æ”¹è„šæœ¬é¡¶éƒ¨çš„ INPUT_DIR å˜é‡ï¼ŒæŒ‡å‘æ‚¨çš„å›¾ç‰‡æ–‡ä»¶å¤¹")
        exit(1)
    
    if not os.path.exists(CFG_PATH):
        print(f"âŒ é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {CFG_PATH}")
        print("è¯·ç¡®ä¿ MiniGPT-4 çš„é…ç½®æ–‡ä»¶å­˜åœ¨")
        exit(1)
    
    # è¿è¡Œæ‰¹é‡å¤„ç†
    batch_process_images(
        input_dir=INPUT_DIR,
        output_dir=OUTPUT_DIR, 
        prompt=PROMPT,
        cfg_path=CFG_PATH,
        gpu_id=GPU_ID,
        font_size=FONT_SIZE
    )
