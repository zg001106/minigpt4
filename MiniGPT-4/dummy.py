import argparse
import os
import random
import numpy as np
import torch
import torch.backends.cudnn as cudnn
from PIL import Image, ImageDraw, ImageFont
import cv2

from minigpt4.common.config import Config
from minigpt4.common.dist_utils import get_rank
from minigpt4.common.registry import registry
from minigpt4.conversation.conversation import Chat, CONV_VISION_Vicuna0, CONV_VISION_LLama2

# imports modules for registration
from minigpt4.datasets.builders import *
from minigpt4.models import *
from minigpt4.processors import *
from minigpt4.runners import *
from minigpt4.tasks import *


def setup_seeds(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    cudnn.benchmark = False
    cudnn.deterministic = True


def init_model(cfg_path, gpu_id=0):
    """åˆå§‹åŒ–MiniGPT-4æ¨¡å‹"""
    # æ¨¡æ‹Ÿå‘½ä»¤è¡Œå‚æ•°
    class Args:
        def __init__(self):
            self.cfg_path = cfg_path
            self.gpu_id = gpu_id
            self.options = None
    
    args = Args()
    cfg = Config(args)
    
    # å¯¹è¯æ¨¡ç‰ˆå­—å…¸
    conv_dict = {'pretrain_vicuna0': CONV_VISION_Vicuna0,
                 'pretrain_llama2': CONV_VISION_LLama2}
    
    print('æ­£åœ¨åˆå§‹åŒ–MiniGPT-4æ¨¡å‹...')
    
    # æ¨¡å‹é…ç½®
    model_config = cfg.model_cfg
    model_config.device_8bit = gpu_id
    model_cls = registry.get_model_class(model_config.arch)
    model = model_cls.from_config(model_config).to(f'cuda:{gpu_id}')
    
    # å¯¹è¯æ¨¡ç‰ˆ
    CONV_VISION = conv_dict[model_config.model_type]
    
    # è§†è§‰å¤„ç†å™¨
    vis_processor_cfg = cfg.datasets_cfg.cc_sbu_align.vis_processor.train
    vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(vis_processor_cfg)
    
    # èŠå¤©å¯¹è±¡
    chat = Chat(model, vis_processor, device=f'cuda:{gpu_id}')
    print('æ¨¡å‹åˆå§‹åŒ–å®Œæˆ!')
    
    return chat, CONV_VISION


def process_single_image(image_path, prompt, chat, conv_vision):
    """å¤„ç†å•å¼ å›¾ç‰‡å¹¶è·å–å›ç­”"""
    try:
        # åˆ›å»ºå¯¹è¯çŠ¶æ€
        chat_state = conv_vision.copy()
        img_list = []
        
        # åŠ è½½å¹¶ä¸Šä¼ å›¾ç‰‡
        image = Image.open(image_path).convert('RGB')
        chat.upload_img(image, chat_state, img_list)
        chat.encode_img(img_list)
        
        # æé—®
        chat.ask(prompt, chat_state)
        
        # è·å–å›ç­”
        answer = chat.answer(conv=chat_state,
                            img_list=img_list,
                            num_beams=1,
                            temperature=1.0,
                            max_new_tokens=300,
                            max_length=2000)[0]
        
        return answer, image
        
    except Exception as e:
        print(f"å¤„ç†å›¾ç‰‡ {image_path} æ—¶å‡ºé”™: {str(e)}")
        return None, None


def create_combined_image(original_image, answer_text, font_size=20):
    """å°†å›ç­”æ–‡æœ¬æ·»åŠ åˆ°å›¾ç‰‡ä¸‹æ–¹ï¼ˆä¿ç•™åŸæœ‰åŠŸèƒ½ç”¨äºå…¼å®¹æ€§ï¼‰"""
    # è½¬æ¢ä¸ºPILå›¾åƒ
    if isinstance(original_image, np.ndarray):
        original_image = Image.fromarray(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
    
    # å›¾ç‰‡å°ºå¯¸
    img_width, img_height = original_image.size
    
    # è®¾ç½®å­—ä½“ï¼ˆå°è¯•ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“ï¼‰
    try:
        # Windowsç³»ç»Ÿå­—ä½“
        font = ImageFont.truetype("arial.ttf", font_size)
    except:
        try:
            # å¤‡ç”¨å­—ä½“
            font = ImageFont.truetype("C:/Windows/Fonts/simhei.ttf", font_size)
        except:
            # é»˜è®¤å­—ä½“
            font = ImageFont.load_default()
    
    # è®¡ç®—æ–‡æœ¬åŒºåŸŸé«˜åº¦
    text_lines = []
    max_width = img_width - 20  # ç•™è¾¹è·
    words = answer_text.split(' ')
    current_line = ""
    
    # å°†æ–‡æœ¬åˆ†è¡Œ
    for word in words:
        test_line = current_line + word + " "
        try:
            bbox = font.getbbox(test_line)
            text_width = bbox[2] - bbox[0]
        except:
            # å¯¹äºæ—§ç‰ˆæœ¬PILï¼Œä½¿ç”¨textsize
            text_width = font.getsize(test_line)[0]
        
        if text_width <= max_width:
            current_line = test_line
        else:
            if current_line:
                text_lines.append(current_line.strip())
                current_line = word + " "
            else:
                text_lines.append(word)
                current_line = ""
    
    if current_line:
        text_lines.append(current_line.strip())
    
    # è®¡ç®—æ–‡æœ¬æ€»é«˜åº¦
    line_height = font_size + 5
    text_height = len(text_lines) * line_height + 20  # é¢å¤–è¾¹è·
    
    # åˆ›å»ºæ–°å›¾ç‰‡ï¼ˆåŸå›¾+æ–‡æœ¬åŒºåŸŸï¼‰
    new_height = img_height + text_height
    combined_image = Image.new('RGB', (img_width, new_height), 'white')
    
    # ç²˜è´´åŸå›¾
    combined_image.paste(original_image, (0, 0))
    
    # ç»˜åˆ¶æ–‡æœ¬
    draw = ImageDraw.Draw(combined_image)
    y_offset = img_height + 10
    
    for line in text_lines:
        draw.text((10, y_offset), line, fill='black', font=font)
        y_offset += line_height
    
    return combined_image


def create_six_panel_comparison_image(rgb_image, event_image, rgb_prompt, event_prompt, rgb_answer, event_answer, font_size=16):
    """åˆ›å»º3è¡Œ2åˆ—çš„6å®«æ ¼å¯¹æ¯”å›¾ç‰‡"""
    
    # è®¾ç½®å­—ä½“
    try:
        font = ImageFont.truetype("arial.ttf", font_size)
        title_font = ImageFont.truetype("arial.ttf", font_size + 2)
    except:
        try:
            font = ImageFont.truetype("C:/Windows/Fonts/simhei.ttf", font_size)
            title_font = ImageFont.truetype("C:/Windows/Fonts/simhei.ttf", font_size + 2)
        except:
            font = ImageFont.load_default()
            title_font = ImageFont.load_default()
    
    # ç»Ÿä¸€å›¾ç‰‡å°ºå¯¸ï¼ˆå–ä¸¤å¼ å›¾ç‰‡çš„æœ€å¤§å°ºå¯¸ï¼‰
    rgb_width, rgb_height = rgb_image.size
    event_width, event_height = event_image.size
    max_width = max(rgb_width, event_width)
    max_height = max(rgb_height, event_height)
    
    # åˆ›å»ºç»Ÿä¸€å°ºå¯¸çš„å›¾ç‰‡
    rgb_resized = Image.new('RGB', (max_width, max_height), 'white')
    event_resized = Image.new('RGB', (max_width, max_height), 'white')
    
    # å±…ä¸­ç²˜è´´åŸå›¾
    rgb_x = (max_width - rgb_width) // 2
    rgb_y = (max_height - rgb_height) // 2
    rgb_resized.paste(rgb_image, (rgb_x, rgb_y))
    
    event_x = (max_width - event_width) // 2
    event_y = (max_height - event_height) // 2
    event_resized.paste(event_image, (event_x, event_y))
    
    # è®¾ç½®é¢æ¿å°ºå¯¸
    panel_width = max_width
    panel_height = max_height
    prompt_height = 80  # æç¤ºè¯åŒºåŸŸé«˜åº¦
    answer_height = 120  # å›ç­”åŒºåŸŸé«˜åº¦
    margin = 10
    
    # åˆ›å»ºæœ€ç»ˆå›¾ç‰‡
    total_width = panel_width * 2 + margin * 3
    total_height = panel_height + prompt_height + answer_height + margin * 4
    
    final_image = Image.new('RGB', (total_width, total_height), 'white')
    draw = ImageDraw.Draw(final_image)
    
    # ç»˜åˆ¶æ ‡é¢˜
    draw.text((margin, margin//2), "RGB Image", fill='black', font=title_font)
    draw.text((panel_width + margin*2, margin//2), "Event Sensor Image", fill='black', font=title_font)
    
    # ç¬¬ä¸€è¡Œï¼šç²˜è´´å›¾ç‰‡
    y_offset = margin + 20
    final_image.paste(rgb_resized, (margin, y_offset))
    final_image.paste(event_resized, (panel_width + margin*2, y_offset))
    
    # ç¬¬äºŒè¡Œï¼šç»˜åˆ¶æç¤ºè¯
    y_offset += panel_height + margin
    
    # RGBæç¤ºè¯åŒºåŸŸ
    rgb_prompt_lines = wrap_text(rgb_prompt, panel_width - margin*2, font)
    draw_text_in_box(draw, rgb_prompt_lines, margin, y_offset, panel_width, prompt_height, font, 'lightblue')
    
    # Eventæç¤ºè¯åŒºåŸŸ
    event_prompt_lines = wrap_text(event_prompt, panel_width - margin*2, font)
    draw_text_in_box(draw, event_prompt_lines, panel_width + margin*2, y_offset, panel_width, prompt_height, font, 'lightgreen')
    
    # ç¬¬ä¸‰è¡Œï¼šç»˜åˆ¶å›ç­”
    y_offset += prompt_height + margin
    
    # RGBå›ç­”åŒºåŸŸ
    rgb_answer_lines = wrap_text(rgb_answer, panel_width - margin*2, font)
    draw_text_in_box(draw, rgb_answer_lines, margin, y_offset, panel_width, answer_height, font, 'lightyellow')
    
    # Eventå›ç­”åŒºåŸŸ
    event_answer_lines = wrap_text(event_answer, panel_width - margin*2, font)
    draw_text_in_box(draw, event_answer_lines, panel_width + margin*2, y_offset, panel_width, answer_height, font, 'lightpink')
    
    return final_image


def wrap_text(text, max_width, font):
    """æ–‡æœ¬æ¢è¡Œå¤„ç†"""
    words = text.split(' ')
    lines = []
    current_line = ""
    
    for word in words:
        test_line = current_line + word + " "
        try:
            bbox = font.getbbox(test_line)
            text_width = bbox[2] - bbox[0]
        except:
            text_width = font.getsize(test_line)[0]
        
        if text_width <= max_width:
            current_line = test_line
        else:
            if current_line:
                lines.append(current_line.strip())
                current_line = word + " "
            else:
                lines.append(word)
                current_line = ""
    
    if current_line:
        lines.append(current_line.strip())
    
    return lines


def draw_text_in_box(draw, text_lines, x, y, width, height, font, bg_color):
    """åœ¨æŒ‡å®šåŒºåŸŸç»˜åˆ¶å¸¦èƒŒæ™¯çš„æ–‡æœ¬"""
    # ç»˜åˆ¶èƒŒæ™¯
    draw.rectangle([x, y, x + width, y + height], fill=bg_color, outline='gray')
    
    # ç»˜åˆ¶æ–‡æœ¬
    line_height = 20
    text_y = y + 5
    
    for line in text_lines:
        if text_y + line_height < y + height:  # ç¡®ä¿ä¸è¶…å‡ºåŒºåŸŸ
            draw.text((x + 5, text_y), line, fill='black', font=font)
            text_y += line_height
        else:
            break


def find_event_image_path(event_dir, rgb_image_name):
    """æ‰¾åˆ°å¯¹åº”çš„Event sensorå›¾ç‰‡"""
    # ç§»é™¤RGBå›¾ç‰‡çš„æ‰©å±•å
    base_name = os.path.splitext(rgb_image_name)[0]
    
    # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']
    
    # å°è¯•æ‰¾åˆ°å¯¹åº”çš„eventå›¾ç‰‡
    for ext in image_extensions:
        event_path = os.path.join(event_dir, base_name + ext)
        if os.path.exists(event_path):
            return event_path
    
    # å¦‚æœæ‰¾ä¸åˆ°å®Œå…¨åŒ¹é…çš„ï¼Œå°è¯•å¯»æ‰¾åŒ…å«base_nameçš„æ–‡ä»¶
    for file in os.listdir(event_dir):
        if base_name.lower() in file.lower():
            return os.path.join(event_dir, file)
    
    return None


def process_rgb_event_comparison(rgb_path, event_path, rgb_prompt, event_prompt, chat, conv_vision):
    """å¤„ç†RGBå’ŒEventå›¾ç‰‡çš„å¯¹æ¯”"""
    try:
        # å¤„ç†RGBå›¾ç‰‡
        rgb_answer, rgb_image = process_single_image(rgb_path, rgb_prompt, chat, conv_vision)
        
        # å¤„ç†Eventå›¾ç‰‡
        event_answer, event_image = process_single_image(event_path, event_prompt, chat, conv_vision)
        
        if rgb_answer and event_answer and rgb_image and event_image:
            return rgb_image, event_image, rgb_answer, event_answer
        else:
            return None, None, None, None
            
    except Exception as e:
        print(f"å¤„ç†å¯¹æ¯”å›¾ç‰‡æ—¶å‡ºé”™: {str(e)}")
        return None, None, None, None


def batch_process_rgb_event_comparison(rgb_dir, event_dir, output_base_dir, rgb_prompts, event_prompt, cfg_path, gpu_id=0):
    """æ‰¹é‡å¤„ç†RGBå’ŒEventå›¾ç‰‡å¯¹æ¯”"""
    # è®¾ç½®éšæœºç§å­
    setup_seeds()
    
    # åˆå§‹åŒ–æ¨¡å‹
    chat, conv_vision = init_model(cfg_path, gpu_id)
    
    # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
    
    # è·å–æ‰€æœ‰RGBå›¾ç‰‡æ–‡ä»¶
    rgb_files = [f for f in os.listdir(rgb_dir) 
                 if any(f.lower().endswith(ext) for ext in image_extensions)]
    
    if not rgb_files:
        print(f"âŒ åœ¨ {rgb_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°RGBå›¾ç‰‡æ–‡ä»¶")
        return
    
    print(f"ğŸ–¼ï¸ æ‰¾åˆ° {len(rgb_files)} å¼ RGBå›¾ç‰‡")
    print(f"ğŸ’¬ å°†ä½¿ç”¨ {len(rgb_prompts)} ä¸ªRGBæç¤ºè¯è¿›è¡Œå¯¹æ¯”")
    print(f"ğŸ¯ Eventå›ºå®šæç¤ºè¯: {event_prompt}")
    print("=" * 80)
    
    # éå†æ¯ä¸ªRGBæç¤ºè¯
    for prompt_idx, rgb_prompt in enumerate(rgb_prompts, 1):
        print(f"\nğŸ”„ æ­£åœ¨å¤„ç†RGBæç¤ºè¯ {prompt_idx}/{len(rgb_prompts)}")
        print(f"ğŸ’¬ RGBæç¤ºè¯: {rgb_prompt}")
        print("-" * 80)
        
        # ä¸ºæ¯ä¸ªRGBæç¤ºè¯åˆ›å»ºè¾“å‡ºç›®å½•
        safe_prompt = "".join(c if c.isalnum() or c in '-_' else '_' for c in rgb_prompt[:50])
        output_dir = os.path.join(output_base_dir, f"rgb_prompt_{prompt_idx:02d}_{safe_prompt}")
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        
        success_count = 0
        
        # å¤„ç†æ¯å¼ RGBå›¾ç‰‡
        for img_idx, rgb_file in enumerate(rgb_files, 1):
            print(f"  ğŸ“¸ ({img_idx}/{len(rgb_files)}) å¤„ç†å›¾ç‰‡: {rgb_file}")
            
            rgb_path = os.path.join(rgb_dir, rgb_file)
            event_path = find_event_image_path(event_dir, rgb_file)
            
            if event_path is None:
                print(f"    âŒ æœªæ‰¾åˆ°å¯¹åº”çš„Eventå›¾ç‰‡")
                continue
            
            # å¤„ç†RGBå’ŒEventå›¾ç‰‡å¯¹æ¯”
            rgb_image, event_image, rgb_answer, event_answer = process_rgb_event_comparison(
                rgb_path, event_path, rgb_prompt, event_prompt, chat, conv_vision
            )
            
            if all([rgb_image, event_image, rgb_answer, event_answer]):
                # åˆ›å»º6å®«æ ¼å¯¹æ¯”å›¾ç‰‡
                comparison_image = create_six_panel_comparison_image(
                    rgb_image, event_image, rgb_prompt, event_prompt, rgb_answer, event_answer
                )
                
                # ä¿å­˜ç»“æœ
                output_filename = f"comparison_{os.path.splitext(rgb_file)[0]}.jpg"
                output_path = os.path.join(output_dir, output_filename)
                comparison_image.save(output_path, 'JPEG', quality=95)
                
                print(f"    âœ… ä¿å­˜å¯¹æ¯”å›¾: {output_filename}")
                print(f"    ğŸ’­ RGBå›ç­”: {rgb_answer[:60]}...")
                print(f"    ğŸ’­ Eventå›ç­”: {event_answer[:60]}...")
                success_count += 1
            else:
                print(f"    âŒ å¤„ç†å¤±è´¥")
        
        # å½“å‰æç¤ºè¯å¤„ç†å®Œæˆçš„ç»Ÿè®¡
        print(f"\nğŸ“Š RGBæç¤ºè¯ {prompt_idx} å¤„ç†å®Œæˆ:")
        print(f"  âœ… æˆåŠŸ: {success_count}/{len(rgb_files)} å¼ å›¾ç‰‡")
        print(f"  ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
        
        if prompt_idx < len(rgb_prompts):
            print(f"\nâ³ å‡†å¤‡å¤„ç†ä¸‹ä¸€ä¸ªRGBæç¤ºè¯...")
    
    print("\n" + "=" * 80)
    print("ğŸ‰ æ‰€æœ‰RGBæç¤ºè¯å¯¹æ¯”å¤„ç†å®Œæˆ!")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {output_base_dir}")
    print("=" * 80)
    """å°†å›ç­”æ–‡æœ¬æ·»åŠ åˆ°å›¾ç‰‡ä¸‹æ–¹"""
    # è½¬æ¢ä¸ºPILå›¾åƒ
    if isinstance(original_image, np.ndarray):
        original_image = Image.fromarray(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
    
    # å›¾ç‰‡å°ºå¯¸
    img_width, img_height = original_image.size
    
    # è®¾ç½®å­—ä½“ï¼ˆå°è¯•ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“ï¼‰
    try:
        # Windowsç³»ç»Ÿå­—ä½“
        font = ImageFont.truetype("arial.ttf", font_size)
    except:
        try:
            # å¤‡ç”¨å­—ä½“
            font = ImageFont.truetype("C:/Windows/Fonts/simhei.ttf", font_size)
        except:
            # é»˜è®¤å­—ä½“
            font = ImageFont.load_default()
    
    # è®¡ç®—æ–‡æœ¬åŒºåŸŸé«˜åº¦
    text_lines = []
    max_width = img_width - 20  # ç•™è¾¹è·
    words = answer_text.split(' ')
    current_line = ""
    
    # å°†æ–‡æœ¬åˆ†è¡Œ
    for word in words:
        test_line = current_line + word + " "
        try:
            bbox = font.getbbox(test_line)
            text_width = bbox[2] - bbox[0]
        except:
            # å¯¹äºæ—§ç‰ˆæœ¬PILï¼Œä½¿ç”¨textsize
            text_width = font.getsize(test_line)[0]
        
        if text_width <= max_width:
            current_line = test_line
        else:
            if current_line:
                text_lines.append(current_line.strip())
                current_line = word + " "
            else:
                text_lines.append(word)
                current_line = ""
    
    if current_line:
        text_lines.append(current_line.strip())
    
    # è®¡ç®—æ–‡æœ¬æ€»é«˜åº¦
    line_height = font_size + 5
    text_height = len(text_lines) * line_height + 20  # é¢å¤–è¾¹è·
    
    # åˆ›å»ºæ–°å›¾ç‰‡ï¼ˆåŸå›¾+æ–‡æœ¬åŒºåŸŸï¼‰
    new_height = img_height + text_height
    combined_image = Image.new('RGB', (img_width, new_height), 'white')
    
    # ç²˜è´´åŸå›¾
    combined_image.paste(original_image, (0, 0))
    
    # ç»˜åˆ¶æ–‡æœ¬
    draw = ImageDraw.Draw(combined_image)
    y_offset = img_height + 10
    
    for line in text_lines:
        draw.text((10, y_offset), line, fill='black', font=font)
        y_offset += line_height
    
    return combined_image


def batch_process_images_with_multiple_prompts(input_dir, output_base_dir, prompts, cfg_path, gpu_id=0):
    """ä½¿ç”¨å¤šä¸ªæç¤ºè¯æ‰¹é‡å¤„ç†å›¾ç‰‡æ–‡ä»¶å¤¹"""
    # è®¾ç½®éšæœºç§å­
    setup_seeds()
    
    # åˆå§‹åŒ–æ¨¡å‹ï¼ˆåªåˆå§‹åŒ–ä¸€æ¬¡ï¼Œæé«˜æ•ˆç‡ï¼‰
    chat, conv_vision = init_model(cfg_path, gpu_id)
    
    # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
    
    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    image_files = []
    for file in os.listdir(input_dir):
        if any(file.lower().endswith(ext) for ext in image_extensions):
            image_files.append(file)
    
    if not image_files:
        print(f"âŒ åœ¨ {input_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return
    
    print(f"ğŸ–¼ï¸ æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    print(f"ğŸ’¬ å°†ä½¿ç”¨ {len(prompts)} ä¸ªæç¤ºè¯å¤„ç†")
    print("=" * 80)
    
    # éå†æ¯ä¸ªæç¤ºè¯
    for prompt_idx, prompt in enumerate(prompts, 1):
        print(f"\nğŸ”„ æ­£åœ¨å¤„ç†æç¤ºè¯ {prompt_idx}/{len(prompts)}")
        print(f"ğŸ’¬ å½“å‰æç¤ºè¯: {prompt}")
        print("-" * 80)
        
        # ä¸ºæ¯ä¸ªæç¤ºè¯åˆ›å»ºå•ç‹¬çš„è¾“å‡ºç›®å½•
        safe_prompt = "".join(c if c.isalnum() or c in '-_' else '_' for c in prompt[:50])
        output_dir = os.path.join(output_base_dir, f"prompt_{prompt_idx:02d}_{safe_prompt}")
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        
        success_count = 0
        
        # éå†å½“å‰æç¤ºè¯ä¸‹çš„æ‰€æœ‰å›¾ç‰‡
        for img_idx, image_file in enumerate(image_files, 1):
            print(f"  ğŸ“¸ ({img_idx}/{len(image_files)}) å¤„ç†å›¾ç‰‡: {image_file}")
            
            image_path = os.path.join(input_dir, image_file)
            
            # è·å–æ¨¡å‹å›ç­”
            answer, original_image = process_single_image(image_path, prompt, chat, conv_vision)
            
            if answer is not None and original_image is not None:
                # åˆ›å»ºç»„åˆå›¾ç‰‡
                combined_image = create_combined_image(original_image, answer)
                
                # ä¿å­˜ç»“æœ
                output_filename = f"result_{os.path.splitext(image_file)[0]}.jpg"
                output_path = os.path.join(output_dir, output_filename)
                combined_image.save(output_path, 'JPEG', quality=95)
                
                print(f"    âœ… ä¿å­˜åˆ°: {output_filename}")
                print(f"    ğŸ’­ å›ç­”: {answer[:80]}...")  # æ˜¾ç¤ºå‰80ä¸ªå­—ç¬¦
                success_count += 1
            else:
                print(f"    âŒ å¤„ç†å¤±è´¥")
        
        # å½“å‰æç¤ºè¯å¤„ç†å®Œæˆçš„ç»Ÿè®¡
        print(f"\nğŸ“Š æç¤ºè¯ {prompt_idx} å¤„ç†å®Œæˆ:")
        print(f"  âœ… æˆåŠŸ: {success_count}/{len(image_files)} å¼ å›¾ç‰‡")
        print(f"  ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
        
        if prompt_idx < len(prompts):
            print(f"\nâ³ å‡†å¤‡å¤„ç†ä¸‹ä¸€ä¸ªæç¤ºè¯...")
    
    print("\n" + "=" * 80)
    print("ğŸ‰ æ‰€æœ‰æç¤ºè¯å¤„ç†å®Œæˆ!")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {output_base_dir}")
    print("=" * 80)


def batch_process_images(input_dir, output_dir, prompt, cfg_path, gpu_id=0):
    """æ‰¹é‡å¤„ç†å›¾ç‰‡æ–‡ä»¶å¤¹"""
    # è®¾ç½®éšæœºç§å­
    setup_seeds()
    
    # åˆå§‹åŒ–æ¨¡å‹
    chat, conv_vision = init_model(cfg_path, gpu_id)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
    
    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    image_files = []
    for file in os.listdir(input_dir):
        if any(file.lower().endswith(ext) for ext in image_extensions):
            image_files.append(file)
    
    print(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    
    # å¤„ç†æ¯å¼ å›¾ç‰‡
    for i, image_file in enumerate(image_files, 1):
        print(f"æ­£åœ¨å¤„ç† ({i}/{len(image_files)}): {image_file}")
        
        image_path = os.path.join(input_dir, image_file)
        
        # è·å–æ¨¡å‹å›ç­”
        answer, original_image = process_single_image(image_path, prompt, chat, conv_vision)
        
        if answer is not None and original_image is not None:
            # åˆ›å»ºç»„åˆå›¾ç‰‡
            combined_image = create_combined_image(original_image, answer)
            
            # ä¿å­˜ç»“æœ
            output_filename = f"result_{os.path.splitext(image_file)[0]}.jpg"
            output_path = os.path.join(output_dir, output_filename)
            combined_image.save(output_path, 'JPEG', quality=95)
            
            print(f"  âœ“ ä¿å­˜åˆ°: {output_path}")
            print(f"  âœ“ å›ç­”: {answer[:100]}...")  # æ˜¾ç¤ºå‰100ä¸ªå­—ç¬¦
        else:
            print(f"  âœ— å¤„ç†å¤±è´¥")
        
        print()  # ç©ºè¡Œåˆ†éš”
    
    print("æ‰¹é‡å¤„ç†å®Œæˆ!")


if __name__ == "__main__":
    # ===== é…ç½®å‚æ•° - è¯·æ ¹æ®æ‚¨çš„å®é™…æƒ…å†µä¿®æ”¹ =====
    
    # è¾“å…¥å’Œè¾“å‡ºè·¯å¾„
    INPUT_DIR = "examples"  # è¾“å…¥å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
    OUTPUT_BASE_DIR = "multi_prompt_results"  # è¾“å‡ºåŸºç¡€ç›®å½•ï¼ˆæ¯ä¸ªæç¤ºè¯ä¼šæœ‰å•ç‹¬çš„å­æ–‡ä»¶å¤¹ï¼‰
    
    # è‡ªå®šä¹‰æç¤ºè¯ - åœ¨è¿™é‡Œè®¾ç½®æ‚¨æƒ³é—®çš„é—®é¢˜
    CUSTOM_PROMPTS = [
        # åŸºç¡€æè¿°ç±»
        "Please describe this image in detail.",
        "What do you see in this image?",
        "Describe the main objects and activities in this picture.",
        
        # ä¸­æ–‡æç¤ºè¯
        "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡ã€‚",
        "è¿™å¼ å›¾ç‰‡ä¸­æœ‰ä»€ä¹ˆï¼Ÿ",
        "æè¿°ä¸€ä¸‹å›¾ç‰‡ä¸­çš„ä¸»è¦å†…å®¹ã€‚",
        
        # ç‰¹å®šä»»åŠ¡ç±»
        "What objects can you see in this image?",
        "Describe the people in this image.",
        "What is the main activity happening in this image?",
        "What emotions or mood does this image convey?",
        "Describe the setting and environment of this image.",
        
        # åˆ†æç±»
        "What is unusual or interesting about this image?",
        "What story does this image tell?",
        "If you were to give this image a title, what would it be?",
        
        # æ‚¨å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šè‡ªå®šä¹‰æç¤ºè¯
        # "Your custom prompt here",
    ]
    
    # å¤„ç†æ¨¡å¼é€‰æ‹©
    PROCESS_MODE = "multiple"  # "single" = åªå¤„ç†ä¸€ä¸ªæç¤ºè¯, "multiple" = å¤„ç†æ‰€æœ‰æç¤ºè¯
    
    # å•ä¸ªæç¤ºè¯æ¨¡å¼çš„é…ç½®ï¼ˆå½“ PROCESS_MODE = "single" æ—¶ä½¿ç”¨ï¼‰
    SELECTED_PROMPT_INDEX = 0  # é€‰æ‹©è¦ä½¿ç”¨çš„æç¤ºè¯ç´¢å¼•
    CUSTOM_PROMPT = None  # æˆ–è€…ç›´æ¥è®¾ç½®è‡ªå®šä¹‰æç¤ºè¯ï¼ˆä¼šè¦†ç›–ä¸Šé¢çš„é€‰æ‹©ï¼‰
    
    # å¤šæç¤ºè¯æ¨¡å¼çš„é…ç½®ï¼ˆå½“ PROCESS_MODE = "multiple" æ—¶ä½¿ç”¨ï¼‰
    PROMPT_RANGE = None  # è®¾ç½®ä¸º (start, end) å¤„ç†éƒ¨åˆ†æç¤ºè¯ï¼Œå¦‚ (0, 5) æˆ– None å¤„ç†æ‰€æœ‰
    
    # æŠ€æœ¯é…ç½®
    CFG_PATH = "eval_configs/minigpt4_eval.yaml"  # é…ç½®æ–‡ä»¶è·¯å¾„
    GPU_ID = 0  # GPU ID
    
    # ===== å¤„ç†æ¨¡å¼åˆ¤æ–­ =====
    print("ğŸ¯ MiniGPT-4 æ‰¹é‡å¤„ç†é…ç½®")
    print("=" * 60)
    print(f"ğŸ“ è¾“å…¥ç›®å½•: {INPUT_DIR}")
    print(f"âš™ï¸ é…ç½®æ–‡ä»¶: {CFG_PATH}")
    print(f"ğŸ”§ GPU ID: {GPU_ID}")
    print("=" * 60)
    
    if PROCESS_MODE == "single":
        # å•ä¸ªæç¤ºè¯æ¨¡å¼
        if CUSTOM_PROMPT is not None:
            final_prompt = CUSTOM_PROMPT
            print(f"ğŸ”¹ æ¨¡å¼: å•ä¸ªè‡ªå®šä¹‰æç¤ºè¯")
            print(f"ğŸ’¬ æç¤ºè¯: {final_prompt}")
        else:
            if 0 <= SELECTED_PROMPT_INDEX < len(CUSTOM_PROMPTS):
                final_prompt = CUSTOM_PROMPTS[SELECTED_PROMPT_INDEX]
                print(f"ğŸ”¹ æ¨¡å¼: å•ä¸ªé€‰å®šæç¤ºè¯")
                print(f"ğŸ’¬ æç¤ºè¯ #{SELECTED_PROMPT_INDEX}: {final_prompt}")
            else:
                print(f"âŒ é”™è¯¯ï¼šæç¤ºè¯ç´¢å¼• {SELECTED_PROMPT_INDEX} è¶…å‡ºèŒƒå›´ (0-{len(CUSTOM_PROMPTS)-1})")
                print("å¯ç”¨çš„æç¤ºè¯åˆ—è¡¨ï¼š")
                for i, prompt in enumerate(CUSTOM_PROMPTS):
                    print(f"  {i}: {prompt}")
                exit(1)
        
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_BASE_DIR}")
        
        # ç¡®è®¤ç»§ç»­
        user_input = input("\næŒ‰ Enter ç»§ç»­ï¼Œæˆ–è¾“å…¥ 'q' é€€å‡º: ").strip().lower()
        if user_input == 'q':
            print("å·²å–æ¶ˆå¤„ç†ã€‚")
            exit(0)
        
        # è¿è¡Œå•ä¸ªæç¤ºè¯å¤„ç†
        batch_process_images(INPUT_DIR, OUTPUT_BASE_DIR, final_prompt, CFG_PATH, GPU_ID)
        
    elif PROCESS_MODE == "multiple":
        # å¤šä¸ªæç¤ºè¯æ¨¡å¼
        if PROMPT_RANGE is not None:
            start_idx, end_idx = PROMPT_RANGE
            selected_prompts = CUSTOM_PROMPTS[start_idx:end_idx]
            print(f"ï¿½ æ¨¡å¼: å¤šæç¤ºè¯å¤„ç† (èŒƒå›´: {start_idx}-{end_idx-1})")
        else:
            selected_prompts = CUSTOM_PROMPTS
            print(f"ğŸ”¹ æ¨¡å¼: å¤šæç¤ºè¯å¤„ç† (å…¨éƒ¨)")
        
        print(f"ğŸ’¬ å°†å¤„ç† {len(selected_prompts)} ä¸ªæç¤ºè¯:")
        for i, prompt in enumerate(selected_prompts):
            print(f"  {i+1:2d}. {prompt}")
        
        print(f"ï¿½ è¾“å‡ºåŸºç¡€ç›®å½•: {OUTPUT_BASE_DIR}")
        print("   (æ¯ä¸ªæç¤ºè¯ä¼šåˆ›å»ºå•ç‹¬çš„å­æ–‡ä»¶å¤¹)")
        
        # ç¡®è®¤ç»§ç»­
        user_input = input(f"\nç»§ç»­å¤„ç† {len(selected_prompts)} ä¸ªæç¤ºè¯ï¼ŸæŒ‰ Enter ç»§ç»­ï¼Œæˆ–è¾“å…¥ 'q' é€€å‡º: ").strip().lower()
        if user_input == 'q':
            print("å·²å–æ¶ˆå¤„ç†ã€‚")
            exit(0)
        
        # è¿è¡Œå¤šæç¤ºè¯å¤„ç†
        batch_process_images_with_multiple_prompts(INPUT_DIR, OUTPUT_BASE_DIR, selected_prompts, CFG_PATH, GPU_ID)
        
    else:
        print(f"âŒ é”™è¯¯ï¼šæœªçŸ¥çš„å¤„ç†æ¨¡å¼ '{PROCESS_MODE}'")
        print("è¯·è®¾ç½® PROCESS_MODE ä¸º 'single' æˆ– 'multiple'")
        exit(1)




