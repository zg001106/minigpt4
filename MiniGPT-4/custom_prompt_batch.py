#!/usr/bin/env python3
"""
MiniGPT-4 è‡ªå®šä¹‰æç¤ºè¯æ‰¹é‡å¤„ç†è„šæœ¬

æ”¯æŒåŠŸèƒ½:
1. è‡ªå®šä¹‰æç¤ºè¯
2. æ‰¹é‡å¤„ç†å¤šä¸ªæç¤ºè¯
3. ä¸ºæ¯ä¸ªæç¤ºè¯åˆ›å»ºå•ç‹¬çš„è¾“å‡ºæ–‡ä»¶å¤¹
4. äº¤äº’å¼æç¤ºè¯é€‰æ‹©
"""

import argparse
import os
import random
import numpy as np
import torch
import torch.backends.cudnn as cudnn
from PIL import Image, ImageDraw, ImageFont
import cv2

from minigpt4.common.config import Config
from minigpt4.common.dist_utils import get_rank
from minigpt4.common.registry import registry
from minigpt4.conversation.conversation import Chat, CONV_VISION_Vicuna0, CONV_VISION_LLama2

# imports modules for registration
from minigpt4.datasets.builders import *
from minigpt4.models import *
from minigpt4.processors import *
from minigpt4.runners import *
from minigpt4.tasks import *

# ===== è‡ªå®šä¹‰æç¤ºè¯åº“ =====
PROMPT_CATEGORIES = {
    "åŸºç¡€æè¿°": [
        "Please describe this image in detail.",
        "What do you see in this image?",
        "Describe the main objects and activities in this picture.",
        "Give me a comprehensive description of this image.",
    ],
    
    "ä¸­æ–‡æç¤º": [
        "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡ã€‚",
        "è¿™å¼ å›¾ç‰‡ä¸­æœ‰ä»€ä¹ˆï¼Ÿ",
        "æè¿°ä¸€ä¸‹å›¾ç‰‡ä¸­çš„ä¸»è¦å†…å®¹ã€‚",
        "è¯·åˆ†æè¿™å¼ å›¾ç‰‡çš„å†…å®¹å’Œå«ä¹‰ã€‚",
    ],
    
    "ç‰©ä½“è¯†åˆ«": [
        "What objects can you see in this image?",
        "List all the items visible in this picture.",
        "Identify and describe the main objects in this image.",
        "What are the most prominent features in this image?",
    ],
    
    "äººç‰©åˆ†æ": [
        "Describe the people in this image.",
        "What are the people doing in this picture?",
        "How many people are in this image and what are they wearing?",
        "Describe the emotions and expressions of people in this image.",
    ],
    
    "åœºæ™¯åˆ†æ": [
        "Describe the setting and environment of this image.",
        "What kind of location is this?",
        "What is the weather or lighting condition in this image?",
        "Describe the background and surroundings.",
    ],
    
    "æ´»åŠ¨åˆ†æ": [
        "What is the main activity happening in this image?",
        "What story does this image tell?",
        "What events are taking place in this picture?",
        "Describe the action or movement in this image.",
    ],
    
    "æƒ…æ„Ÿåˆ†æ": [
        "What emotions or mood does this image convey?",
        "What feelings does this image evoke?",
        "Describe the atmosphere of this image.",
        "What is the emotional tone of this picture?",
    ],
    
    "åˆ›æ„åˆ†æ": [
        "What is unusual or interesting about this image?",
        "If you were to give this image a title, what would it be?",
        "What makes this image unique or special?",
        "Tell me something creative about this image.",
    ],
    
    "æŠ€æœ¯åˆ†æ": [
        "Describe the composition and visual elements of this image.",
        "What colors dominate this image?",
        "Describe the lighting and shadows in this image.",
        "What is the perspective or viewpoint of this image?",
    ]
}

# æ‚¨çš„è‡ªå®šä¹‰æç¤ºè¯ - åœ¨è¿™é‡Œæ·»åŠ æ‚¨æƒ³è¦çš„é—®é¢˜
MY_CUSTOM_PROMPTS = [
    # åœ¨è¿™é‡Œæ·»åŠ æ‚¨çš„è‡ªå®šä¹‰æç¤ºè¯
    "Your custom question 1 here",
    "Your custom question 2 here",
    # å¯ä»¥æ·»åŠ æ›´å¤š...
]

def setup_seeds(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    cudnn.benchmark = False
    cudnn.deterministic = True

def init_model(cfg_path, gpu_id=0):
    """åˆå§‹åŒ–MiniGPT-4æ¨¡å‹"""
    class Args:
        def __init__(self):
            self.cfg_path = cfg_path
            self.gpu_id = gpu_id
            self.options = None
    
    args = Args()
    cfg = Config(args)
    
    conv_dict = {'pretrain_vicuna0': CONV_VISION_Vicuna0,
                 'pretrain_llama2': CONV_VISION_LLama2}
    
    print('ğŸš€ æ­£åœ¨åˆå§‹åŒ–MiniGPT-4æ¨¡å‹...')
    
    model_config = cfg.model_cfg
    model_config.device_8bit = gpu_id
    model_cls = registry.get_model_class(model_config.arch)
    model = model_cls.from_config(model_config).to(f'cuda:{gpu_id}')
    
    CONV_VISION = conv_dict[model_config.model_type]
    
    vis_processor_cfg = cfg.datasets_cfg.cc_sbu_align.vis_processor.train
    vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(vis_processor_cfg)
    
    chat = Chat(model, vis_processor, device=f'cuda:{gpu_id}')
    print('âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ!')
    
    return chat, CONV_VISION

def process_single_image(image_path, prompt, chat, conv_vision):
    """å¤„ç†å•å¼ å›¾ç‰‡å¹¶è·å–å›ç­”"""
    try:
        chat_state = conv_vision.copy()
        img_list = []
        
        image = Image.open(image_path).convert('RGB')
        chat.upload_img(image, chat_state, img_list)
        chat.encode_img(img_list)
        
        chat.ask(prompt, chat_state)
        
        answer = chat.answer(conv=chat_state,
                            img_list=img_list,
                            num_beams=1,
                            temperature=1.0,
                            max_new_tokens=300,
                            max_length=2000)[0]
        
        return answer, image
        
    except Exception as e:
        print(f"âŒ å¤„ç†å›¾ç‰‡ {image_path} æ—¶å‡ºé”™: {str(e)}")
        return None, None

def create_combined_image(original_image, answer_text, font_size=16):
    """å°†å›ç­”æ–‡æœ¬æ·»åŠ åˆ°å›¾ç‰‡ä¸‹æ–¹"""
    if isinstance(original_image, np.ndarray):
        original_image = Image.fromarray(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
    
    img_width, img_height = original_image.size
    
    try:
        font = ImageFont.truetype("arial.ttf", font_size)
    except:
        try:
            font = ImageFont.truetype("C:/Windows/Fonts/simhei.ttf", font_size)
        except:
            font = ImageFont.load_default()
    
    text_lines = []
    max_width = img_width - 20
    words = answer_text.split(' ')
    current_line = ""
    
    for word in words:
        test_line = current_line + word + " "
        try:
            bbox = font.getbbox(test_line)
            text_width = bbox[2] - bbox[0]
        except:
            text_width = font.getsize(test_line)[0]
        
        if text_width <= max_width:
            current_line = test_line
        else:
            if current_line:
                text_lines.append(current_line.strip())
                current_line = word + " "
            else:
                text_lines.append(word)
                current_line = ""
    
    if current_line:
        text_lines.append(current_line.strip())
    
    line_height = font_size + 5
    text_height = len(text_lines) * line_height + 20
    
    new_height = img_height + text_height
    combined_image = Image.new('RGB', (img_width, new_height), 'white')
    
    combined_image.paste(original_image, (0, 0))
    
    draw = ImageDraw.Draw(combined_image)
    y_offset = img_height + 10
    
    for line in text_lines:
        draw.text((10, y_offset), line, fill='black', font=font)
        y_offset += line_height
    
    return combined_image

def show_prompt_menu():
    """æ˜¾ç¤ºæç¤ºè¯èœå•"""
    print("\n" + "=" * 60)
    print("ğŸ“ å¯ç”¨çš„æç¤ºè¯ç±»åˆ«")
    print("=" * 60)
    
    all_prompts = []
    category_index = 0
    
    for category, prompts in PROMPT_CATEGORIES.items():
        print(f"\nğŸ“‚ {category}:")
        for i, prompt in enumerate(prompts):
            print(f"  {len(all_prompts):2d}. {prompt}")
            all_prompts.append(prompt)
    
    if MY_CUSTOM_PROMPTS and MY_CUSTOM_PROMPTS[0] != "Your custom question 1 here":
        print(f"\nğŸ“‚ æˆ‘çš„è‡ªå®šä¹‰æç¤ºè¯:")
        for prompt in MY_CUSTOM_PROMPTS:
            print(f"  {len(all_prompts):2d}. {prompt}")
            all_prompts.append(prompt)
    
    return all_prompts

def select_prompts():
    """äº¤äº’å¼é€‰æ‹©æç¤ºè¯"""
    all_prompts = show_prompt_menu()
    
    print("\n" + "=" * 60)
    print("ğŸ¯ é€‰æ‹©æç¤ºè¯")
    print("=" * 60)
    print("é€‰æ‹©æ–¹å¼:")
    print("1. è¾“å…¥å•ä¸ªæ•°å­— (å¦‚: 5)")
    print("2. è¾“å…¥å¤šä¸ªæ•°å­—ï¼Œç”¨é€—å·åˆ†éš” (å¦‚: 1,3,5)")
    print("3. è¾“å…¥èŒƒå›´ (å¦‚: 1-5)")
    print("4. è¾“å…¥ 'all' ä½¿ç”¨æ‰€æœ‰æç¤ºè¯")
    print("5. è¾“å…¥ 'custom' ç›´æ¥è¾“å…¥è‡ªå®šä¹‰æç¤ºè¯")
    
    user_input = input("\nè¯·è¾“å…¥æ‚¨çš„é€‰æ‹©: ").strip()
    
    if user_input.lower() == 'all':
        return all_prompts
    elif user_input.lower() == 'custom':
        custom_prompt = input("è¯·è¾“å…¥æ‚¨çš„è‡ªå®šä¹‰æç¤ºè¯: ").strip()
        return [custom_prompt] if custom_prompt else []
    elif '-' in user_input:
        try:
            start, end = map(int, user_input.split('-'))
            return [all_prompts[i] for i in range(start, min(end+1, len(all_prompts))) if 0 <= i < len(all_prompts)]
        except:
            print("âŒ èŒƒå›´æ ¼å¼é”™è¯¯")
            return []
    elif ',' in user_input:
        try:
            indices = [int(x.strip()) for x in user_input.split(',')]
            return [all_prompts[i] for i in indices if 0 <= i < len(all_prompts)]
        except:
            print("âŒ æ•°å­—æ ¼å¼é”™è¯¯")
            return []
    else:
        try:
            index = int(user_input)
            if 0 <= index < len(all_prompts):
                return [all_prompts[index]]
            else:
                print("âŒ ç´¢å¼•è¶…å‡ºèŒƒå›´")
                return []
        except:
            print("âŒ è¾“å…¥æ ¼å¼é”™è¯¯")
            return []

def batch_process_with_prompts(input_dir, output_base_dir, prompts, cfg_path, gpu_id=0):
    """ä½¿ç”¨å¤šä¸ªæç¤ºè¯æ‰¹é‡å¤„ç†"""
    if not prompts:
        print("âŒ æ²¡æœ‰é€‰æ‹©ä»»ä½•æç¤ºè¯")
        return
    
    setup_seeds()
    chat, conv_vision = init_model(cfg_path, gpu_id)
    
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
    image_files = [f for f in os.listdir(input_dir) 
                   if any(f.lower().endswith(ext) for ext in image_extensions)]
    
    if not image_files:
        print(f"âŒ åœ¨ {input_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return
    
    print(f"\nğŸ–¼ï¸ æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    print(f"ğŸ’¬ å°†ä½¿ç”¨ {len(prompts)} ä¸ªæç¤ºè¯å¤„ç†")
    
    for prompt_idx, prompt in enumerate(prompts, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ”„ å¤„ç†æç¤ºè¯ {prompt_idx}/{len(prompts)}")
        print(f"ğŸ’¬ æç¤ºè¯: {prompt}")
        print(f"{'='*60}")
        
        # ä¸ºæ¯ä¸ªæç¤ºè¯åˆ›å»ºå•ç‹¬çš„è¾“å‡ºç›®å½•
        safe_prompt = "".join(c if c.isalnum() or c in '-_' else '_' for c in prompt[:50])
        output_dir = os.path.join(output_base_dir, f"prompt_{prompt_idx:02d}_{safe_prompt}")
        os.makedirs(output_dir, exist_ok=True)
        
        success_count = 0
        for img_idx, image_file in enumerate(image_files, 1):
            print(f"  ğŸ“¸ ({img_idx}/{len(image_files)}) {image_file}")
            
            image_path = os.path.join(input_dir, image_file)
            answer, original_image = process_single_image(image_path, prompt, chat, conv_vision)
            
            if answer and original_image:
                combined_image = create_combined_image(original_image, answer)
                output_filename = f"result_{os.path.splitext(image_file)[0]}.jpg"
                output_path = os.path.join(output_dir, output_filename)
                combined_image.save(output_path, 'JPEG', quality=95)
                
                print(f"    âœ… å›ç­”: {answer[:60]}...")
                success_count += 1
            else:
                print(f"    âŒ å¤„ç†å¤±è´¥")
        
        print(f"\nğŸ“Š æç¤ºè¯ {prompt_idx} å®Œæˆ: {success_count}/{len(image_files)} å¼ å›¾ç‰‡æˆåŠŸå¤„ç†")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")

def main():
    """ä¸»å‡½æ•°"""
    # åŸºç¡€é…ç½®
    INPUT_DIR = "examples"  # ä¿®æ”¹ä¸ºæ‚¨çš„å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
    OUTPUT_BASE_DIR = "custom_prompt_results"  # è¾“å‡ºåŸºç¡€ç›®å½•
    CFG_PATH = "eval_configs/minigpt4_eval.yaml"
    GPU_ID = 0
    
    print("ğŸ¯ MiniGPT-4 è‡ªå®šä¹‰æç¤ºè¯æ‰¹é‡å¤„ç†")
    print("=" * 60)
    print(f"ğŸ“ è¾“å…¥ç›®å½•: {INPUT_DIR}")
    print(f"ğŸ“ è¾“å‡ºåŸºç¡€ç›®å½•: {OUTPUT_BASE_DIR}")
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(INPUT_DIR):
        print(f"âŒ é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {INPUT_DIR}")
        print("è¯·ä¿®æ”¹è„šæœ¬ä¸­çš„ INPUT_DIR å˜é‡")
        return
    
    # é€‰æ‹©æç¤ºè¯
    selected_prompts = select_prompts()
    
    if not selected_prompts:
        print("âŒ æ²¡æœ‰é€‰æ‹©æœ‰æ•ˆçš„æç¤ºè¯ï¼Œç¨‹åºé€€å‡º")
        return
    
    print(f"\nâœ… å·²é€‰æ‹© {len(selected_prompts)} ä¸ªæç¤ºè¯:")
    for i, prompt in enumerate(selected_prompts, 1):
        print(f"  {i}. {prompt}")
    
    # ç¡®è®¤å¤„ç†
    confirm = input(f"\nç»§ç»­å¤„ç† {len(selected_prompts)} ä¸ªæç¤ºè¯ï¼Ÿ(y/N): ").strip().lower()
    if confirm != 'y':
        print("å·²å–æ¶ˆå¤„ç†")
        return
    
    # å¼€å§‹æ‰¹é‡å¤„ç†
    batch_process_with_prompts(INPUT_DIR, OUTPUT_BASE_DIR, selected_prompts, CFG_PATH, GPU_ID)
    
    print(f"\nğŸ‰ æ‰€æœ‰å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {OUTPUT_BASE_DIR}")

if __name__ == "__main__":
    main()
